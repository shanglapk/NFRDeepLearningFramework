from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from tensorflow.keras.constraints import max_norm
#kernel_regularizer = regularizers.L2()
from sklearn.metrics import multilabel_confusion_matrix
from sklearn.metrics import accuracy_score, f1_score, precision_score, 
recall_score, classification_report, confusion_matrix, multilabel_confusion_matrix,
from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping
from keras.layers import BatchNormalization
create_model():
    model = Sequential()
    #model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM,
                       #embedding_regularizer=l2(0.0005),
                      # input_length=X.shape[1]))
    model.add(Dense(units=2128,activation="relu",input_dim=X.shape[1]))
    model.add(Dense(units= 5,activation="softmax"))
    #optimizer = Adam(lr=0.000015,beta_1=0.9,beta_2=0.999)
    #model.compile(optimizer=optimizer,metrics=["accuracy"],loss=categorical_crossentropy)
    #return model
  # model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    print(model.summary())
    # compile the model
   # opt = adam_v2.Adam (learning_rate = 0.001, decay=1e-6)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

num_epochs = 100
model = create_model()
history = model.fit(X_train, Y_train, epochs=num_epochs, validation_data=(X_test,  Y_test), verbose=2)
import matplotlib.pyplot as plt
 
import matplotlib.pyplot as plt
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('ANN Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('ANN Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
# print confusion matrix
y_pred = model.predict(X_test)
y_pred = (y_pred >= 0.5)
Model_test = model.evaluate(X_test,Y_test)
print("the test accuracy of the model is",Model_test)
#y_pred = np.argmax(y_pred, axis=1) 
#Get the confusion matrix
#cf_matrix = confusion_matrix(Y_test, y_pred)
cm = confusion_matrix(Y_test.argmax(axis=1),y_pred.argmax(axis=1))
print(cm)
ax = sns.heatmap(cm, annot=True, cmap='Blues')

ax.set_title('ANN Model Confusion Matrix\n\n');
ax.set_xlabel('\nPredicted NFR Category')
ax.set_ylabel('Actual NFR Category ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['M', 'O', 'PE','SE','US'])
ax.yaxis.set_ticklabels(['M', 'O', 'PE','SE','US'])

## Display the visualization of the Confusion Matrix.
plt.show()
#from sklearn.metrics import confusion_matrix
#cm = confusion_matrix(Y_test, y_pred)
#print(cm)
# calculate the accuray
from sklearn.metrics import accuracy_score
score = accuracy_score(y_pred, Y_test)
print(score)
from sklearn.metrics import classification_report
target_names = ['Maintainability', 'Operability', 'Performance','Security','Usability']
print(classification_report(Y_test, y_pred, target_names=target_names))
