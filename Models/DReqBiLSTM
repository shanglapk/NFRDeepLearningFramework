import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout,SpatialDropout1D, Activation, Embedding
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import LeaveOneOut
import datetime
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import accuracy_score, f1_score, precision_score, \
recall_score, classification_report, confusion_matrix, multilabel_confusion_matrix,
from tensorflow.keras.optimizers import Adam
from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping
from keras.layers import BatchNormalization
def create_model():
 model = Sequential()
 model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1], mask_z
 model.add(Dropout(0.2))
 model.add(Bidirectional(LSTM(100, return_sequences=True)))
 model.add(BatchNormalization())
 # model.add(Dropout(0.2))
 model.add(Bidirectional(LSTM(50, return_sequences=True)))
 model.add(Dropout(0.2))
 # model.add(BatchNormalization())
 model.add(Bidirectional(LSTM(32, return_sequences=True)))
 model.add(Dropout(0.5))
 model.add(Flatten())
 model.add(Dense(5, activation='softmax'))
 # Instantiate Focal loss 
 model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accur
 print(model.summary())
 return model
num_epochs = 100
model = create_model()
history = model.fit(X_train, Y_train, epochs=num_epochs, batch_size = 10,callbacks=
import matplotlib.pyplot as plt
import matplotlib.pyplot as plt
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('DReqBiLSTM model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('DReqBiLSTM model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
# print confusion matrix
plt.show()
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
y_pred = model.predict(X_test)
y_pred = (y_pred >= 0.5)
cm = confusion_matrix(Y_test.argmax(axis=1),y_pred.argmax(axis=1))
print(cm)
ax = sns.heatmap(cm, annot=True, cmap='Blues')
ax.set_title('DReqBiLSTM Model Confusion Matrix\n\n');
ax.set_xlabel('\nPredicted NFR Category')
ax.set_ylabel('Actual NFR Category ');
## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['M', 'O', 'PE','SE','US'])
ax.yaxis.set_ticklabels(['M', 'O', 'PE','SE','US'])
from sklearn.metrics import accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
score = accuracy_score(y_pred, Y_test)
print(score)
from sklearn.metrics import classification_report
print(classification_report(Y_test, y_pred, target_names=target_names))
