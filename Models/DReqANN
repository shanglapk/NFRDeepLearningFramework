from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from tensorflow.keras.constraints import max_norm
#kernel_regularizer = regularizers.L2()
from sklearn.metrics import multilabel_confusion_matrix
from sklearn.metrics import accuracy_score, f1_score, precision_score, 
recall_score, classification_report, confusion_matrix, multilabel_confusion_matrix,
from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping
from keras.layers import BatchNormalization

#preparing NFR for for ANN
tfidv = TfidfVectorizer(max_features=5000, min_df=1, smooth_idf=True, norm = 'l2')
X = tfidv.fit_transform(df['sentence'].values)
print("term frequence are",X)
print(X.sort_indices())

Y = pd.get_dummies(df['class_name'])
Y = pd.get_dummies(df['class_name']).values
print('Shape of label tensor:', Y.shape)
# pandas.factorize() method helps to get the numeric representation of an array by identifying distinct values
y, y_uniques=pd.factorize(df['class_name'], sort=True)
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 34, stratify=Y)
# Model creation

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, verbose=1)
early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, mode='auto')
def create_model():
    model = Sequential()
    model.add(Dense(units=2128,activation="relu",input_dim=X.shape[1]))
    model.add(Dropout(0.2))
    model.add(Dense(units=256,activation="relu"))
    model.add(Dropout(0.7))
    model.add(Dense(units=128,activation="relu"))
    model.add(Dropout(0.8))
    model.add(Dense(units= 5,activation="softmax"))
    print(model.summary())
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

num_epochs = 100
model = create_model()
history = model.fit(X_train, Y_train, epochs=num_epochs, batch_size = 32,callbacks=[reduce_lr, early_stop], validation_data=(X_test,  Y_test), verbose=2)
import matplotlib.pyplot as plt
 
import matplotlib.pyplot as plt
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('DReqANN model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('DReqANN model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# print confusion matrix
y_pred = model.predict(X_test)
y_pred = (y_pred >= 0.5)
cm = confusion_matrix(Y_test.argmax(axis=1),y_pred.argmax(axis=1))
print(cm)
ax = sns.heatmap(cm, annot=True, cmap='Blues')
ax.set_title('DReqANN Model Confusion Matrix\n\n');
ax.set_xlabel('\nPredicted NFR Category')
ax.set_ylabel('Actual NFR Category ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['M', 'O', 'PE','SE','US'])
ax.yaxis.set_ticklabels(['M', 'O', 'PE','SE','US']) 
from sklearn.metrics import accuracy_score
score = accuracy_score(y_pred, Y_test)
print(score)
from sklearn.metrics import classification_report
target_names = ['Maintainability', 'Operability', 'Performance','Security','Usability']
print(classification_report(Y_test, y_pred, target_names=target_names))
oss, accuracy = model.evaluate(X_train, Y_train, verbose=False)
print("Training Accuracy: {:.4f}".format(accuracy))
loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy))
#preparing x for ANN
tfidv = TfidfVectorizer(max_features=5000, min_df=1, smooth_idf=True, norm = 'l2')
X = tfidv.fit_transform(df['sentence'].values)
print("term frequence are",X)
print(X.sort_indices())

Y = pd.get_dummies(df['class_name'])
Y = pd.get_dummies(df['class_name']).values
print('Shape of label tensor:', Y.shape)
# pandas.factorize() method helps to get the numeric representation of an array by identifying distinct values
y, y_uniques=pd.factorize(df['class_name'], sort=True)
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 34, stratify=Y)
# Model creation
from tensorflow.keras.optimizers import Adam
from keras.optimizers import adam_v2
from tensorflow.keras import regularizers
from tensorflow.keras.constraints import max_norm
#kernel_regularizer = regularizers.L2()
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, verbose=1)
early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, mode='auto')
def create_model():
    model = Sequential()
    model.add(Dense(units=2128,activation="relu",input_dim=X.shape[1]))
    model.add(Dropout(0.2))
    model.add(Dense(units=256,activation="relu"))
    model.add(Dropout(0.7))
    model.add(Dense(units=128,activation="relu"))
    model.add(Dropout(0.8))
    model.add(Dense(units= 5,activation="softmax"))
    print(model.summary())
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

num_epochs = 100
model = create_model()
history = model.fit(X_train, Y_train, epochs=num_epochs, batch_size = 32,callbacks=[reduce_lr, early_stop], validation_data=(X_test,  Y_test), verbose=2)
import matplotlib.pyplot as plt
 
import matplotlib.pyplot as plt
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('DReqANN model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('DReqANN model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# print confusion matrix
y_pred = model.predict(X_test)
y_pred = (y_pred >= 0.5)
cm = confusion_matrix(Y_test.argmax(axis=1),y_pred.argmax(axis=1))
print(cm)
ax = sns.heatmap(cm, annot=True, cmap='Blues')
ax.set_title('DReqANN Model Confusion Matrix\n\n');
ax.set_xlabel('\nPredicted NFR Category')
ax.set_ylabel('Actual NFR Category ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['M', 'O', 'PE','SE','US'])
ax.yaxis.set_ticklabels(['M', 'O', 'PE','SE','US']) 
from sklearn.metrics import accuracy_score
score = accuracy_score(y_pred, Y_test)
print(score)
from sklearn.metrics import classification_report
target_names = ['Maintainability', 'Operability', 'Performance','Security','Usability']
print(classification_report(Y_test, y_pred, target_names=target_names))
oss, accuracy = model.evaluate(X_train, Y_train, verbose=False)
print("Training Accuracy: {:.4f}".format(accuracy))
loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy))
##################################################################################################################################
DReqANN Model and Training Process
###################################################################################################################################
term frequence are (0, 1733) 0.32537348243650027
 (0, 89) 0.49676218590467563
 (0, 765) 0.43963261808195053
 (0, 650) 0.4159217051179256
 (0, 1587) 0.5301808407633759
 (1, 556) 0.2219565024518366
 (1, 2011) 0.47692424101681774
 (1, 1076) 0.47692424101681774
 (1, 802) 0.39895838922871907
 (1, 1657) 0.4565081414936087
 (1, 650) 0.35812619018230096
 (2, 1933) 0.30312415380390506
 (2, 122) 0.473662723773161
 (2, 1670) 0.473662723773161
 (2, 1729) 0.40699051249539975
 (2, 1495) 0.5419978951388823
 (3, 535) 0.3363312698242577
 (3, 734) 0.2890498722844782
 (3, 2017) 0.17153664797029736
 (3, 69) 0.30782588757326484
 (3, 1091) 0.34650528112520335
 (3, 1674) 0.29318528753345074
 (3, 1670) 0.32772926583641676
 (3, 1729) 0.5631969549978009
 (3, 1733) 0.22029308916844217
 : :
 (911, 2033) 0.29371296564974575
 (911, 1003) 0.3134719016257172
 (911, 962) 0.2326639066985016
 (911, 1372) 0.2560342377065305
 (911, 600) 0.29371296564974575
 (911, 2015) 0.17399246720403141
 (911, 1952) 0.23039691505816087
 (911, 1933) 0.18315654058075687
 (911, 556) 0.15241157950464396
 (912, 13) 0.45254613643753794
 (912, 1531) 0.31079437717590047
 (912, 2071) 0.31079437717590047
 (912, 78) 0.31079437717590047
 (912, 2046) 0.2905554676788573
 (912, 2059) 0.39549585480356214
 (912, 56) 0.3019889431041052
 (912, 1190) 0.28881830155236593
 (912, 437) 0.2999496219523907
 (913, 645) 0.4008620264454442
 (913, 343) 0.4008620264454442
 (913, 117) 0.29778045490260385
 (913, 703) 0.42095457277883724
 (913, 406) 0.3786202986484731
 (913, 1521) 0.28022792981319056
 (913, 556) 0.43687789672475236
====================================================================================================================================
Shape of label tensor: (914, 5)
Model: "sequential_18"
_________________________________________________________________
Layer (type) Output Shape Param # 
=================================================================
dense_77 (Dense) (None, 2128) 4496464 
 
dropout_59 (Dropout) (None, 2128) 0 
dense_78 (Dense) (None, 256) 545024 
dropout_60 (Dropout) (None, 256) 0 
dense_79 (Dense) (None, 128) 32896 
dropout_61 (Dropout) (None, 128) 0 
dense_80 (Dense) (None, 5) 645 
=================================================================
Total params: 5,075,029
Trainable params: 5,075,029
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
23/23 - 2s - loss: 1.5489 - accuracy: 0.3625 - val_loss: 1.4664 - val_accuracy: 0.
3880 - lr: 0.0010 - 2s/epoch - 97ms/step
Epoch 2/100
23/23 - 2s - loss: 1.4323 - accuracy: 0.3844 - val_loss: 1.3579 - val_accuracy: 0.
3880 - lr: 0.0010 - 2s/epoch - 68ms/step
Epoch 3/100
23/23 - 2s - loss: 1.2362 - accuracy: 0.4405 - val_loss: 1.1659 - val_accuracy: 0.
4918 - lr: 0.0010 - 2s/epoch - 80ms/step
Epoch 4/100
23/23 - 2s - loss: 1.0301 - accuracy: 0.5417 - val_loss: 1.0247 - val_accuracy: 0.
6885 - lr: 0.0010 - 2s/epoch - 70ms/step
Epoch 5/100
23/23 - 2s - loss: 0.8003 - accuracy: 0.7031 - val_loss: 0.8631 - val_accuracy: 0.
7705 - lr: 0.0010 - 2s/epoch - 67ms/step
Epoch 6/100
23/23 - 2s - loss: 0.5641 - accuracy: 0.8181 - val_loss: 0.7053 - val_accuracy: 0.
8142 - lr: 0.0010 - 2s/epoch - 67ms/step
Epoch 7/100
23/23 - 2s - loss: 0.3923 - accuracy: 0.8687 - val_loss: 0.6266 - val_accuracy: 0.
8306 - lr: 0.0010 - 2s/epoch - 71ms/step
Epoch 8/100
23/23 - 2s - loss: 0.2856 - accuracy: 0.9248 - val_loss: 0.6437 - val_accuracy: 0.
8470 - lr: 0.0010 - 2s/epoch - 67ms/step
Epoch 9/100
23/23 - 2s - loss: 0.2058 - accuracy: 0.9439 - val_loss: 0.6564 - val_accuracy: 0.
8525 - lr: 0.0010 - 2s/epoch - 67ms/step
Epoch 10/100
23/23 - 2s - loss: 0.1561 - accuracy: 0.9576 - val_loss: 0.6981 - val_accuracy: 0.
8470 - lr: 0.0010 - 2s/epoch - 68ms/step
Epoch 11/100
23/23 - 1s - loss: 0.1230 - accuracy: 0.9672 - val_loss: 0.6877 - val_accuracy: 0.
8579 - lr: 0.0010 - 1s/epoch - 65ms/step
Epoch 12/100
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
23/23 - 2s - loss: 0.0991 - accuracy: 0.9726 - val_loss: 0.7155 - val_accuracy: 0.
8634 - lr: 0.0010 - 2s/epoch - 72ms/step
Epoch 13/100
23/23 - 1s - loss: 0.1010 - accuracy: 0.9672 - val_loss: 0.7175 - val_accuracy: 0.
8689 - lr: 1.0000e-04 - 1s/epoch - 63ms/step
Epoch 14/100
23/23 - 1s - loss: 0.0882 - accuracy: 0.9699 - val_loss: 0.7218 - val_accuracy: 0.
8634 - lr: 1.0000e-04 - 1s/epoch - 65ms/step
Epoch 15/100
23/23 - 2s - loss: 0.0906 - accuracy: 0.9822 - val_loss: 0.7295 - val_accuracy: 0.
8634 - lr: 1.0000e-04 - 2s/epoch - 68ms/step
Epoch 16/100
23/23 - 2s - loss: 0.0954 - accuracy: 0.9767 - val_loss: 0.7403 - val_accuracy: 0.
8689 - lr: 1.0000e-04 - 2s/epoch - 80ms/step
Epoch 17/100
Epoch 17: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
23/23 - 2s - loss: 0.0771 - accuracy: 0.9740 - val_loss: 0.7494 - val_accuracy: 0.
8634 - lr: 1.0000e-04 - 2s/epoch - 75ms/step
========================================================================================================================================
NFR Classification Report of  DReqANN Model
========================================================================================================================================
                    precision  recall  f1-score   support

Maintainability       0.95      0.70      0.81        27
    Operability       0.87      0.84      0.85        31
    Performance       0.86      0.83      0.84        23
       Security       0.88      0.90      0.89        71
      Usability       0.90      0.84      0.87        31

      micro avg       0.89      0.84      0.86       183
      macro avg       0.89      0.82      0.85       183
   weighted avg       0.89      0.84      0.86       183
    samples avg       0.84      0.84      0.84       183

==========================================================================================================================================
NFR Classification DReqANN Model Confusion Matrix
==========================================================================================================================================
[[21  1  0  4  1]
 [ 1 26  0  4  0]
 [ 2  1 19  1  0]
 [ 1  1  3 64  2]
 [ 4  1  0  0 26]]
