from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
from tensorflow.keras.constraints import max_norm
#kernel_regularizer = regularizers.L2()
from sklearn.metrics import multilabel_confusion_matrix
from sklearn.metrics import accuracy_score, f1_score, precision_score, 
recall_score, classification_report, confusion_matrix, multilabel_confusion_matrix,
from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping
from keras.layers import BatchNormalization

#preparing NFR for for ANN
tfidv = TfidfVectorizer(max_features=5000, min_df=1, smooth_idf=True, norm = 'l2')
X = tfidv.fit_transform(df['sentence'].values)
print("term frequence are",X)
print(X.sort_indices())

Y = pd.get_dummies(df['class_name'])
Y = pd.get_dummies(df['class_name']).values
print('Shape of label tensor:', Y.shape)
# pandas.factorize() method helps to get the numeric representation of an array by identifying distinct values
y, y_uniques=pd.factorize(df['class_name'], sort=True)
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 34, stratify=Y)
# Model creation

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, verbose=1)
early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, mode='auto')
def create_model():
    model = Sequential()
    model.add(Dense(units=2128,activation="relu",input_dim=X.shape[1]))
    model.add(Dropout(0.2))
    model.add(Dense(units=256,activation="relu"))
    model.add(Dropout(0.7))
    model.add(Dense(units=128,activation="relu"))
    model.add(Dropout(0.8))
    model.add(Dense(units= 5,activation="softmax"))
    print(model.summary())
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

num_epochs = 100
model = create_model()
history = model.fit(X_train, Y_train, epochs=num_epochs, batch_size = 32,callbacks=[reduce_lr, early_stop], validation_data=(X_test,  Y_test), verbose=2)
import matplotlib.pyplot as plt
 
import matplotlib.pyplot as plt
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('DReqANN model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('DReqANN model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# print confusion matrix
y_pred = model.predict(X_test)
y_pred = (y_pred >= 0.5)
cm = confusion_matrix(Y_test.argmax(axis=1),y_pred.argmax(axis=1))
print(cm)
ax = sns.heatmap(cm, annot=True, cmap='Blues')
ax.set_title('DReqANN Model Confusion Matrix\n\n');
ax.set_xlabel('\nPredicted NFR Category')
ax.set_ylabel('Actual NFR Category ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['M', 'O', 'PE','SE','US'])
ax.yaxis.set_ticklabels(['M', 'O', 'PE','SE','US']) 
from sklearn.metrics import accuracy_score
score = accuracy_score(y_pred, Y_test)
print(score)
from sklearn.metrics import classification_report
target_names = ['Maintainability', 'Operability', 'Performance','Security','Usability']
print(classification_report(Y_test, y_pred, target_names=target_names))
oss, accuracy = model.evaluate(X_train, Y_train, verbose=False)
print("Training Accuracy: {:.4f}".format(accuracy))
loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy))
#preparing x for ANN
tfidv = TfidfVectorizer(max_features=5000, min_df=1, smooth_idf=True, norm = 'l2')
X = tfidv.fit_transform(df['sentence'].values)
print("term frequence are",X)
print(X.sort_indices())

Y = pd.get_dummies(df['class_name'])
Y = pd.get_dummies(df['class_name']).values
print('Shape of label tensor:', Y.shape)
# pandas.factorize() method helps to get the numeric representation of an array by identifying distinct values
y, y_uniques=pd.factorize(df['class_name'], sort=True)
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 34, stratify=Y)
# Model creation
from tensorflow.keras.optimizers import Adam
from keras.optimizers import adam_v2
from tensorflow.keras import regularizers
from tensorflow.keras.constraints import max_norm
#kernel_regularizer = regularizers.L2()
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6, verbose=1)
early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, mode='auto')
def create_model():
    model = Sequential()
    model.add(Dense(units=2128,activation="relu",input_dim=X.shape[1]))
    model.add(Dropout(0.2))
    model.add(Dense(units=256,activation="relu"))
    model.add(Dropout(0.7))
    model.add(Dense(units=128,activation="relu"))
    model.add(Dropout(0.8))
    model.add(Dense(units= 5,activation="softmax"))
    print(model.summary())
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

num_epochs = 100
model = create_model()
history = model.fit(X_train, Y_train, epochs=num_epochs, batch_size = 32,callbacks=[reduce_lr, early_stop], validation_data=(X_test,  Y_test), verbose=2)
import matplotlib.pyplot as plt
 
import matplotlib.pyplot as plt
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('DReqANN model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('DReqANN model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# print confusion matrix
y_pred = model.predict(X_test)
y_pred = (y_pred >= 0.5)
cm = confusion_matrix(Y_test.argmax(axis=1),y_pred.argmax(axis=1))
print(cm)
ax = sns.heatmap(cm, annot=True, cmap='Blues')
ax.set_title('DReqANN Model Confusion Matrix\n\n');
ax.set_xlabel('\nPredicted NFR Category')
ax.set_ylabel('Actual NFR Category ');

## Ticket labels - List must be in alphabetical order
ax.xaxis.set_ticklabels(['M', 'O', 'PE','SE','US'])
ax.yaxis.set_ticklabels(['M', 'O', 'PE','SE','US']) 
from sklearn.metrics import accuracy_score
score = accuracy_score(y_pred, Y_test)
print(score)
from sklearn.metrics import classification_report
target_names = ['Maintainability', 'Operability', 'Performance','Security','Usability']
print(classification_report(Y_test, y_pred, target_names=target_names))
oss, accuracy = model.evaluate(X_train, Y_train, verbose=False)
print("Training Accuracy: {:.4f}".format(accuracy))
loss, accuracy = model.evaluate(X_test, Y_test, verbose=False)
print("Testing Accuracy:  {:.4f}".format(accuracy))
##################################################################################################################################
DReqANN Model and Training Process
###################################################################################################################################
Shape of label tensor: (914, 5)
Model: "sequential_18"
_________________________________________________________________
Layer (type) Output Shape Param # 
=================================================================
dense_77 (Dense) (None, 2128) 4496464 
 
dropout_59 (Dropout) (None, 2128) 0 
dense_78 (Dense) (None, 256) 545024 
dropout_60 (Dropout) (None, 256) 0 
dense_79 (Dense) (None, 128) 32896 
dropout_61 (Dropout) (None, 128) 0 
dense_80 (Dense) (None, 5) 645 
=================================================================
Total params: 5,075,029
Trainable params: 5,075,029
Non-trainable params: 0
_________________________________________________________________
None
Epoch 1/100
23/23 - 2s - loss: 1.5489 - accuracy: 0.3625 - val_loss: 1.4664 - val_accuracy: 0.
3880 - lr: 0.0010 - 2s/epoch - 97ms/step
Epoch 2/100
23/23 - 2s - loss: 1.4323 - accuracy: 0.3844 - val_loss: 1.3579 - val_accuracy: 0.
3880 - lr: 0.0010 - 2s/epoch - 68ms/step
Epoch 3/100
23/23 - 2s - loss: 1.2362 - accuracy: 0.4405 - val_loss: 1.1659 - val_accuracy: 0.
4918 - lr: 0.0010 - 2s/epoch - 80ms/step
Epoch 4/100
23/23 - 2s - loss: 1.0301 - accuracy: 0.5417 - val_loss: 1.0247 - val_accuracy: 0.
6885 - lr: 0.0010 - 2s/epoch - 70ms/step
Epoch 5/100
23/23 - 2s - loss: 0.8003 - accuracy: 0.7031 - val_loss: 0.8631 - val_accuracy: 0.
7705 - lr: 0.0010 - 2s/epoch - 67ms/step
Epoch 6/100
23/23 - 2s - loss: 0.5641 - accuracy: 0.8181 - val_loss: 0.7053 - val_accuracy: 0.
8142 - lr: 0.0010 - 2s/epoch - 67ms/step
Epoch 7/100
23/23 - 2s - loss: 0.3923 - accuracy: 0.8687 - val_loss: 0.6266 - val_accuracy: 0.
8306 - lr: 0.0010 - 2s/epoch - 71ms/step
Epoch 8/100
23/23 - 2s - loss: 0.2856 - accuracy: 0.9248 - val_loss: 0.6437 - val_accuracy: 0.
8470 - lr: 0.0010 - 2s/epoch - 67ms/step
Epoch 9/100
23/23 - 2s - loss: 0.2058 - accuracy: 0.9439 - val_loss: 0.6564 - val_accuracy: 0.
8525 - lr: 0.0010 - 2s/epoch - 67ms/step
Epoch 10/100
23/23 - 2s - loss: 0.1561 - accuracy: 0.9576 - val_loss: 0.6981 - val_accuracy: 0.
8470 - lr: 0.0010 - 2s/epoch - 68ms/step
Epoch 11/100
23/23 - 1s - loss: 0.1230 - accuracy: 0.9672 - val_loss: 0.6877 - val_accuracy: 0.
8579 - lr: 0.0010 - 1s/epoch - 65ms/step
Epoch 12/100
Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
23/23 - 2s - loss: 0.0991 - accuracy: 0.9726 - val_loss: 0.7155 - val_accuracy: 0.
8634 - lr: 0.0010 - 2s/epoch - 72ms/step
Epoch 13/100
23/23 - 1s - loss: 0.1010 - accuracy: 0.9672 - val_loss: 0.7175 - val_accuracy: 0.
8689 - lr: 1.0000e-04 - 1s/epoch - 63ms/step
Epoch 14/100
23/23 - 1s - loss: 0.0882 - accuracy: 0.9699 - val_loss: 0.7218 - val_accuracy: 0.
8634 - lr: 1.0000e-04 - 1s/epoch - 65ms/step
Epoch 15/100
23/23 - 2s - loss: 0.0906 - accuracy: 0.9822 - val_loss: 0.7295 - val_accuracy: 0.
8634 - lr: 1.0000e-04 - 2s/epoch - 68ms/step
Epoch 16/100
23/23 - 2s - loss: 0.0954 - accuracy: 0.9767 - val_loss: 0.7403 - val_accuracy: 0.
8689 - lr: 1.0000e-04 - 2s/epoch - 80ms/step
Epoch 17/100
Epoch 17: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
23/23 - 2s - loss: 0.0771 - accuracy: 0.9740 - val_loss: 0.7494 - val_accuracy: 0.
8634 - lr: 1.0000e-04 - 2s/epoch - 75ms/step

